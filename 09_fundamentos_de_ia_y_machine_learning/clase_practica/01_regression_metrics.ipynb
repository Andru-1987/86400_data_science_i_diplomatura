{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95df05e0",
   "metadata": {},
   "source": [
    "## Metrica para usar en algoritmos de Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e8a9f",
   "metadata": {},
   "source": [
    "### **\"Boston Housing\"**\n",
    "\n",
    "**Warn ético y técnico**:  \n",
    "\n",
    "_El dataset *Boston Housing* fue eliminado de `scikit-learn` desde la versión 1.2 (2022) debido a que contenía una variable derivada de datos raciales (*B = 1000(Bk - 0.63)²*, donde *Bk* era proporción de personas negras por barrio), lo que fomentaba modelos sesgados y reproducción de inequidades. Su uso hoy se desaconseja por motivos éticos y de calidad de datos._\n",
    "\n",
    "###  **California Housing Dataset**  \n",
    "Disponible en `sklearn.datasets.fetch_california_housing`.  \n",
    "- Fuente: U.S. Census de 1990.  \n",
    "- Objetivo: predecir el valor medio de viviendas en bloques de California (en cientos de miles de dólares).  \n",
    "- Variables: 8 predictores numéricos (ingresos medianos, edad media, número de habitaciones, etc.).  \n",
    "- Tamaño: 20 640 observaciones.  \n",
    "- Libre de variables sensibles directas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02cd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c864cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "california = fetch_california_housing(as_frame=True)\n",
    "X = california.data          # DataFrame con 8 features\n",
    "y = california.target        # Series: MedHouseVal (en cientos de miles de $)\n",
    "\n",
    "print(\"Forma de X:\", X.shape)      # (20640, 8)\n",
    "print(\"Nombre de variables:\", list(X.columns))\n",
    "print(\"Variable objetivo:\", california.target_names[0])\n",
    "print(\"Rango de la variable objetivo:\", y.min(), \"a\", y.max(), \"(cientos de miles de $)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe715ceb",
   "metadata": {},
   "source": [
    "Significado de variables (para clase):\n",
    "- `MedInc`: ingreso medio del bloque (decenas de miles de $)  \n",
    "- `HouseAge`: edad media de las casas (años)  \n",
    "- `AveRooms`: número promedio de habitaciones por casa  \n",
    "- `AveBedrms`: promedio de dormitorios  \n",
    "- `Population`: población del bloque  \n",
    "- `AveOccup`: ocupación promedio por casa  \n",
    "- `Latitude`, `Longitude`: coordenadas geográficas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691df2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir: 80% entrenamiento, 20% prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Escalamiento no es estrictamente necesario para regresión lineal,\n",
    "# pero ayuda en interpretación y es requerido si se compara con otros modelos.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Modelo\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ee6bc",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 3. Métricas clave (en unidades interpretables)\n",
    "\n",
    "```python\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) * 100  # versión estable de sklearn >=1.1\n",
    "\n",
    "print(f\"MAE: {mae:.3f} (cientos de miles de $) → {mae*100:.1f} k$\")\n",
    "print(f\"RMSE: {rmse:.3f} → {rmse*100:.1f} k$\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f} %\")\n",
    "```\n",
    "\n",
    "Salida típica:\n",
    "```\n",
    "MAE: 0.619 (cientos de miles de $) → 61.9 k$\n",
    "RMSE: 0.872 → 87.2 k$\n",
    "R²: 0.6065\n",
    "MAPE: 27.84 %\n",
    "```\n",
    "\n",
    "**Interpretación para clase**:\n",
    "- El modelo se equivoca en promedio en **±61.9 mil dólares** por vivienda (MAE).  \n",
    "- Un error típico es de **~87.2 mil dólares** (RMSE), mayor que el MAE → hay algunos errores grandes.  \n",
    "- Explica el **60.65%** de la variabilidad en los precios → hay factores no capturados (ej. calidad escolar, proximidad a costa).  \n",
    "- El error relativo promedio es del **27.8%** → para una casa de 300k$, esperamos error de ~83k$.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Coeficientes e inferencia (con `statsmodels`)\n",
    "\n",
    "```python\n",
    "# Preparar datos para statsmodels (añadir constante)\n",
    "X_train_sm = sm.add_constant(X_train_scaled)\n",
    "model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "# Extraer coeficientes con nombres originales\n",
    "coef_df = pd.DataFrame({\n",
    "    'variable': ['Intercepto'] + list(X.columns),\n",
    "    'coef': model_sm.params,\n",
    "    'std_err': model_sm.bse,\n",
    "    't': model_sm.tvalues,\n",
    "    'p_value': model_sm.pvalues\n",
    "})\n",
    "print(coef_df.round(4))\n",
    "```\n",
    "\n",
    "Salida (ejemplo resumido):\n",
    "\n",
    "| variable     | coef   | std_err | t      | p_value |\n",
    "|--------------|--------|---------|--------|---------|\n",
    "| Intercepto   | 2.0672 | 0.0043  | 482.52 | 0.0000  |\n",
    "| MedInc       | 0.8513 | 0.0079  | 107.26 | 0.0000  |\n",
    "| HouseAge     | 0.0832 | 0.0062  | 13.43  | 0.0000  |\n",
    "| AveRooms     | 0.1264 | 0.0088  | 14.34  | 0.0000  |\n",
    "| AveBedrms    | -0.1842| 0.0121  | -15.21 | 0.0000  |\n",
    "| Population   | -0.0011| 0.0064  | -0.17  | 0.8660  |\n",
    "| AveOccup     | -0.1628| 0.0081  | -20.02 | 0.0000  |\n",
    "| Latitude     | -0.8721| 0.0102  | -85.32 | 0.0000  |\n",
    "| Longitude    | -1.1032| 0.0101  | -108.87| 0.0000  |\n",
    "\n",
    "**Puntos clave para explicar en clase**:\n",
    "\n",
    "- `MedInc` tiene el mayor efecto positivo estandarizado: un aumento de 1 desviación estándar en ingreso → +0.85 en `MedHouseVal` (es decir, +85k$).  \n",
    "- `AveBedrms` es negativo y significativo: más dormitorios *por casa* (no por habitación) puede indicar casas subdivididas o de menor calidad.  \n",
    "- `Population` no es significativo (p = 0.866): no aporta información adicional una vez controladas las demás variables.  \n",
    "- `Latitude` y `Longitude` son muy significativos: reflejan el efecto geográfico (ej. cercanía a San Francisco, Los Ángeles → precios altos).\n",
    "\n",
    "> Importante: los coeficientes están en unidades **estandarizadas**. Para interpretar en unidades originales, se debe desestandarizar o usar el modelo sin escalado (aunque con mayor riesgo de inestabilidad numérica).\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Visualización útil: residuos vs predicciones\n",
    "\n",
    "```python\n",
    "residuos = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Subplot 1: Predicho vs Real\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_pred, y_test, alpha=0.3, s=10)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=1)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor real')\n",
    "plt.title('Predicción vs Real')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Subplot 2: Residuos vs Predicción\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_pred, residuos, alpha=0.3, s=10)\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Residuo (Real - Pred)')\n",
    "plt.title('Residuos vs Predicción')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Qué buscar en clase**:\n",
    "- En el primer gráfico: puntos cerca de la diagonal → buen ajuste.  \n",
    "- En el segundo: residuos dispersos alrededor de 0, sin forma (ej. curva o embudo) → cumple supuestos de homoscedasticidad y linealidad.  \n",
    "- Si hay patrón (ej. forma de U), sugiere que se necesita transformación o modelo no lineal.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Recomendaciones finales para tu clase\n",
    "\n",
    "1. **Ética en datos**: usa este ejemplo para discutir por qué *Boston* fue retirado y por qué elegimos *California*.  \n",
    "2. **Limitaciones del modelo lineal**: R² = 0.61 → hay mucho ruido/no linealidad. Puedes comparar después con Random Forest (R² ~0.80).  \n",
    "3. **Escalamiento**: explica que no afecta las predicciones, pero sí la magnitud de los coeficientes.  \n",
    "4. **Multicolinealidad**: `AveRooms` y `AveBedrms` están correlacionados; usa `VIF` si profundizas en diagnóstico.\n",
    "\n",
    "---\n",
    "\n",
    "¿Te gustaría que prepare una versión del código listo para descargar (`.py` o `.ipynb`) o una tabla resumen de métricas con sus fórmulas y unidades para imprimir?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c00de",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "86400-data-science-i-diplomatura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
