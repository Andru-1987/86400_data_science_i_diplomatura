{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40236a9b",
   "metadata": {},
   "source": [
    "\n",
    "## **Variables y tipos de datos**\n",
    "\n",
    "### **Noción de variable**\n",
    "\n",
    "Representa una característica medible de la unidad de observación.\n",
    "Ejemplo: “edad”, “género”, “nivel de ingresos”.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tipos de variables**\n",
    "\n",
    "| Tipo                              | Subtipo    | Ejemplo           | Observaciones                               |\n",
    "| --------------------------------- | ---------- | ----------------- | ------------------------------------------- |\n",
    "| **Cuantitativa**                  | *Discreta* | Nº de hijos       | Solo enteros                                |\n",
    "|                                   | *Continua* | Peso, temperatura | Puede tener decimales                       |\n",
    "| **Cualitativa**                   | *Nominal*  | Color, país       | Sin orden                                   |\n",
    "|                                   | *Ordinal*  | Nivel educativo   | Con jerarquía                               |\n",
    "| **Lógica**                        | —          | Verdadero/Falso   | Muy usada en ML                             |\n",
    "| **Metadatos / Alta cardinalidad** | —          | ID cliente        | Identificadores, no se modelan directamente |\n",
    "\n",
    "*En machine learning*: elegir bien el tipo de variable define el tipo de preprocesamiento (por ejemplo, normalización, codificación, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Medidas de resumen**\n",
    "\n",
    "### 4.1. **Cuantitativas**\n",
    "\n",
    "| Medida                  | Qué mide                          | Fórmula o idea                          |\n",
    "| ----------------------- | --------------------------------- | --------------------------------------- |\n",
    "| **Media**               | Promedio                          | (Σxᵢ)/n                                 |\n",
    "| **Mediana**             | Valor central                     | Divide el conjunto en dos mitades       |\n",
    "| **Moda**                | Valor más frecuente               | Aplica también a categorías             |\n",
    "| **Varianza (s²)**       | Dispersión cuadrática             | Promedio de las diferencias al cuadrado |\n",
    "| **Desvío estándar (s)** | Dispersión en unidades originales | √varianza                               |\n",
    "\n",
    "*Interpretación*:\n",
    "Si dos variables tienen igual media pero distinta desviación estándar, una es más “variable” o dispersa que la otra.\n",
    "\n",
    "---\n",
    "\n",
    "### **Cualitativas**\n",
    "\n",
    "Solo se analizan **frecuencias o proporciones**.\n",
    "Medidas de tendencia central\n",
    "    *Moda*: Es la categoría que aparece con mayor frecuencia en el conjunto de datos. Esta es la única medida de tendencia central que se puede usar para datos cualitativos nominales. \n",
    "    *Mediana*: Solo se puede calcular para datos cualitativos de tipo ordinal (que se pueden ordenar). \n",
    "Ejemplo:\n",
    "\n",
    "| Categoría | Frecuencia | Porcentaje |\n",
    "| --------- | ---------- | ---------- |\n",
    "| Masculino | 60         | 60%        |\n",
    "| Femenino  | 40         | 40%        |\n",
    "\n",
    "La **moda categórica** es la categoría más común."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8186c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef770212",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/Andru-1987/csv_files_ds/refs/heads/main/glasdoordata.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df = df.assign(\n",
    "    performance=df[\"performance\"].astype(\"category\"),\n",
    "    seniority=df[\"seniority\"].astype(\"category\")\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04246ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\nColumnas numéricas: {list(numeric_columns)}\")\n",
    "\n",
    "# Calcular varianza y desviación estándar para cada columna numérica\n",
    "print(\"\\n VARIANZA Y DESVIACIÓN ESTÁNDAR\")\n",
    "results = {}\n",
    "\n",
    "for col in numeric_columns:\n",
    "    # Eliminar valores NaN para el cálculo\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    # Cálculos manuales\n",
    "    media = np.mean(data)\n",
    "    n = len(data)\n",
    "    \n",
    "    # Varianza poblacional (dividiendo por N)\n",
    "    varianza_poblacional = np.sum((data - media)**2) / n\n",
    "    \n",
    "    # Varianza muestral (dividiendo por n-1)\n",
    "    varianza_muestral = np.sum((data - media)**2) / (n - 1)\n",
    "    \n",
    "    # Desviación estándar\n",
    "    desv_std_poblacional = np.sqrt(varianza_poblacional)\n",
    "    desv_std_muestral = np.sqrt(varianza_muestral)\n",
    "    \n",
    "    # Usando funciones de numpy (para verificación)\n",
    "    var_numpy = np.var(data, ddof=1)  # ddof=1 para muestra, ddof=0 para población\n",
    "    std_numpy = np.std(data, ddof=1)\n",
    "    \n",
    "    results[col] = {\n",
    "        'media': media,\n",
    "        'varianza_poblacional': varianza_poblacional,\n",
    "        'varianza_muestral': varianza_muestral,\n",
    "        'desv_std_poblacional': desv_std_poblacional,\n",
    "        'desv_std_muestral': desv_std_muestral,\n",
    "        'n': n\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(f\"Muestra (n): {n}\")\n",
    "    print(f\"Media: {media:.2f}\")\n",
    "    print(f\"Varianza (poblacional): {varianza_poblacional:.2f}\")\n",
    "    print(f\"Varianza (muestral): {varianza_muestral:.2f}\")\n",
    "    print(f\"Desviación estándar (poblacional): {desv_std_poblacional:.2f}\")\n",
    "    print(f\"Desviación estándar (muestral): {desv_std_muestral:.2f}\")\n",
    "    print(f\"Verificación con numpy - Varianza: {var_numpy:.2f}\")\n",
    "    print(f\"Verificación con numpy - Desv. std: {std_numpy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_desviacion(df:pd.DataFrame, column:str):\n",
    "    \n",
    "    data = df[column].dropna()\n",
    "    media = results[column]['media']\n",
    "    desv_std = results[column]['desv_std_muestral']\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Histograma\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(data, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(media, color='red', linestyle='--', linewidth=2, label=f'Media: {media:.2f}')\n",
    "    plt.axvline(media + desv_std, color='orange', linestyle='--', linewidth=2, label=f'±1σ')\n",
    "    plt.axvline(media - desv_std, color='orange', linestyle='--', linewidth=2)\n",
    "    plt.axvline(media + 2*desv_std, color='green', linestyle='--', linewidth=1, label=f'±2σ')\n",
    "    plt.axvline(media - 2*desv_std, color='green', linestyle='--', linewidth=1)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title(f'Distribución de {column}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(data)\n",
    "    plt.ylabel(column)\n",
    "    plt.title(f'Boxplot de {column}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "    display_desviacion(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9068869",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESUMEN COMPARATIVO\")\n",
    "resumen_data = []\n",
    "for col in numeric_columns:\n",
    "    media = results[col]['media']\n",
    "    varianza = results[col]['varianza_muestral']\n",
    "    desv_std = results[col]['desv_std_muestral']\n",
    "    coef_variacion = (desv_std / media) * 100 if media != 0 else float('inf')\n",
    "    \n",
    "    resumen_data.append({\n",
    "        'Columna': col,\n",
    "        'Media': media,\n",
    "        'Varianza': varianza,\n",
    "        'Desv_Std': desv_std,\n",
    "        'Coef_Variacion_%': coef_variacion,\n",
    "        'n': results[col]['n']\n",
    "    })\n",
    "\n",
    "# Crear DataFrame\n",
    "resumen_df = pd.DataFrame(resumen_data)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(resumen_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127c445",
   "metadata": {},
   "source": [
    "Mide la variabilidad relativa de los datos en comparación con su tamaño promedio. A diferencia de la desviación estándar (que es una medida absoluta), el CV permite comparar la variabilidad entre diferentes conjuntos de datos, incluso si tienen:\n",
    "\n",
    "* Diferentes unidades de medida\n",
    "* Diferentes escalas\n",
    "* Diferentes magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a48e69",
   "metadata": {},
   "source": [
    "```sh\n",
    "CV < 15%    → BAJA variabilidad (datos muy consistentes)\n",
    "15% ≤ CV < 30% → MODERADA variabilidad  \n",
    "CV ≥ 30%    → ALTA variabilidad (datos muy dispersos)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80153264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n DATAFRAME CON ANÁLISIS INTERPRETATIVO \")\n",
    "\n",
    "analisis_df = pd.DataFrame({\n",
    "    'Columna': numeric_columns,\n",
    "    'Media': [results[col]['media'] for col in numeric_columns],\n",
    "    'Varianza': [results[col]['varianza_muestral'] for col in numeric_columns],\n",
    "    'Desv_Std': [results[col]['desv_std_muestral'] for col in numeric_columns],\n",
    "    'CV_%': [(results[col]['desv_std_muestral'] / results[col]['media']) * 100 \n",
    "             if results[col]['media'] != 0 else float('inf') \n",
    "             for col in numeric_columns],\n",
    "    'Rango_68%_Inferior': [results[col]['media'] - results[col]['desv_std_muestral'] \n",
    "                          for col in numeric_columns],\n",
    "    'Rango_68%_Superior': [results[col]['media'] + results[col]['desv_std_muestral'] \n",
    "                          for col in numeric_columns],\n",
    "    'Interpretacion_CV': [\n",
    "        \"BAJA variabilidad\" if ((results[col]['desv_std_muestral'] / results[col]['media']) * 100) < 15 \n",
    "        else \"MODERADA variabilidad\" if ((results[col]['desv_std_muestral'] / results[col]['media']) * 100) < 30 \n",
    "        else \"ALTA variabilidad\" \n",
    "        for col in numeric_columns\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Formatear el DataFrame\n",
    "analisis_df_formateado = analisis_df.round({\n",
    "    'Media': 2,\n",
    "    'Varianza': 2,\n",
    "    'Desv_Std': 2,\n",
    "    'CV_%': 1,\n",
    "    'Rango_68%_Inferior': 2,\n",
    "    'Rango_68%_Superior': 2\n",
    "})\n",
    "\n",
    "print(analisis_df_formateado.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ceb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESUMEN FINAL - MEDIDAS DE VARIABILIDAD\")\n",
    "\n",
    "styled_df = (analisis_df_formateado.style\n",
    "    .format({\n",
    "        'Media': '{:.2f}',\n",
    "        'Varianza': '{:.2f}', \n",
    "        'Desv_Std': '{:.2f}',\n",
    "        'CV_%': '{:.1f}%',\n",
    "        'Rango_68%_Inferior': '{:.2f}',\n",
    "        'Rango_68%_Superior': '{:.2f}'\n",
    "    })\n",
    "    .background_gradient(subset=['Varianza'], cmap='Reds')\n",
    "    .background_gradient(subset=['Desv_Std'], cmap='Blues')\n",
    "    .background_gradient(subset=['CV_%'], cmap='viridis')\n",
    "    )\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c246a6",
   "metadata": {},
   "source": [
    "## Intervalos de confianza\n",
    "\n",
    "Los intervalos de confianza permiten estimar un rango donde se encuentra un parámetro poblacional con un cierto nivel de confianza.\n",
    "Los IC nos permiten expresar no solo una estimación puntual, sino también el margen de error de esa estimación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b75de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_intervalo_confianza(data, confianza=0.95):\n",
    "    n = len(data)\n",
    "    media = np.mean(data)\n",
    "    desv_std = np.std(data, ddof=1)  # Muestral\n",
    "    \n",
    "    # Valor crítico t (usamos t-student para muestras pequeñas, normal para grandes)\n",
    "    if n < 30:\n",
    "        valor_critico = stats.t.ppf((1 + confianza) / 2, n-1)\n",
    "    else:\n",
    "        valor_critico = stats.norm.ppf((1 + confianza) / 2)\n",
    "    \n",
    "    # Error estándar\n",
    "    error_estandar = desv_std / np.sqrt(n)\n",
    "    \n",
    "    # Margen de error\n",
    "    margen_error = valor_critico * error_estandar\n",
    "    \n",
    "    # Intervalo de confianza\n",
    "    ic_inferior = media - margen_error\n",
    "    ic_superior = media + margen_error\n",
    "    \n",
    "    return {\n",
    "        'media': media,\n",
    "        'n': n,\n",
    "        'desv_std': desv_std,\n",
    "        'error_estandar': error_estandar,\n",
    "        'margen_error': margen_error,\n",
    "        'ic_inferior': ic_inferior,\n",
    "        'ic_superior': ic_superior,\n",
    "        'valor_critico': valor_critico,\n",
    "        'confianza': confianza\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular IC para cada columna numérica\n",
    "resultados_ic = {}\n",
    "niveles_confianza = [0.90, 0.95, 0.99]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    data = df[col].dropna()\n",
    "    resultados_ic[col] = {}\n",
    "    \n",
    "    for confianza in niveles_confianza:\n",
    "        resultados_ic[col][confianza] = calcular_intervalo_confianza(data, confianza)\n",
    "\n",
    "# Mostrar resultados en tabla\n",
    "print(\"TABLA DE INTERVALOS DE CONFIANZA\")\n",
    "\n",
    "tabla_ic = []\n",
    "for col in numeric_columns:\n",
    "    for confianza in niveles_confianza:\n",
    "        ic = resultados_ic[col][confianza]\n",
    "        tabla_ic.append({\n",
    "            'Variable': col,\n",
    "            'Confianza': f\"{confianza*100:.0f}%\",\n",
    "            'Media': ic['media'],\n",
    "            'IC_Inferior': ic['ic_inferior'],\n",
    "            'IC_Superior': ic['ic_superior'],\n",
    "            'Margen_Error': ic['margen_error'],\n",
    "            'n': ic['n']\n",
    "        })\n",
    "\n",
    "df_ic = pd.DataFrame(tabla_ic)\n",
    "print(df_ic.round(2).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b383dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparacion_niveles_confianza(df,column):\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    confianzas = [0.90, 0.95, 0.99]\n",
    "    colores = ['lightblue', 'blue', 'darkblue']\n",
    "    anchos = [0.6, 0.8, 1.0]\n",
    "\n",
    "    for i, confianza in enumerate(confianzas):\n",
    "        ic = resultados_ic[column][confianza]\n",
    "        \n",
    "        plt.hlines(y=len(confianzas)-i, xmin=ic['ic_inferior'], xmax=ic['ic_superior'], \n",
    "                color=colores[i], linewidth=5, label=f'{confianza*100:.0f}% Confianza')\n",
    "        plt.plot(ic['media'], len(confianzas)-i, 'ro', markersize=8)\n",
    "\n",
    "    plt.axvline(x=resultados_ic[column][0.95]['media'], color='red', linestyle='--', alpha=0.7, label='Media')\n",
    "    plt.xlabel('Valor')\n",
    "    plt.ylabel('Nivel de Confianza')\n",
    "    plt.title(f'Intervalos de Confianza para {column} - Diferentes Niveles')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.yticks([1, 2, 3], ['99%', '95%', '90%'])\n",
    "\n",
    "    # Añadir valores\n",
    "    for i, confianza in enumerate(confianzas):\n",
    "        ic = resultados_ic[column][confianza]\n",
    "        plt.text(ic['ic_inferior'], len(confianzas)-i + 0.1, f'{ic[\"ic_inferior\"]:.1f}', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "        plt.text(ic['ic_superior'], len(confianzas)-i + 0.1, f'{ic[\"ic_superior\"]:.1f}', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "    comparacion_niveles_confianza(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INTERPRETACIÓN PRÁCTICA DE LOS INTERVALOS DE CONFIANZA\")\n",
    "\n",
    "\n",
    "for col in numeric_columns:\n",
    "    ic_95 = resultados_ic[col][0.95]\n",
    "    \n",
    "    print(f\"\\n {col.upper()}:\")\n",
    "    print(f\"   • Con 95% de confianza, el valor real poblacional está entre:\")\n",
    "    print(f\"     {ic_95['ic_inferior']:.2f} y {ic_95['ic_superior']:.2f}\")\n",
    "    print(f\"   • Margen de error: ±{ic_95['margen_error']:.2f}\")\n",
    "    print(f\"   • Precisión: {ic_95['margen_error']/ic_95['media']*100:.1f}% de la media\")\n",
    "    \n",
    "    # Interpretación de precisión\n",
    "    precision = (ic_95['margen_error'] / ic_95['media']) * 100\n",
    "    if precision < 5:\n",
    "        calidad = \"EXCELENTE precisión\"\n",
    "    elif precision < 10:\n",
    "        calidad = \"BUENA precisión\"\n",
    "    elif precision < 20:\n",
    "        calidad = \"PRECISIÓN MODERADA\"\n",
    "    else:\n",
    "        calidad = \"BAJA precisión\"\n",
    "    \n",
    "    print(f\"   • Calidad de estimación: {calidad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75b325",
   "metadata": {},
   "source": [
    "### Deteccion de Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f482a0",
   "metadata": {},
   "source": [
    "El método del Rango Intercuartílico (IQR) se usa para identificar valores atípicos (\\(outliers\\)) en un conjunto de datos, especialmente cuando no hay una distribución normal. Sirve para encontrar valores que están inusualmente altos o bajos en comparación con el resto de los datos, y es robusto porque no se ve afectado por valores extremos. También se utiliza para entender la dispersión de la mitad central de los datos y como una medida de variabilidad junto con la mediana\n",
    "\n",
    "_El método intercuartil (RIC) para la detección de valores atípicos utiliza una escala de 1,5 para detectarlos , ya que se ajusta con mayor precisión a la distribución gaussiana . Por lo tanto, el método determina que cualquier punto de datos que se encuentre 1,5 puntos por debajo del cuartil inferior o por encima del cuartil superior es un valor atípico._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ab258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers_iqr(data, columna):\n",
    "    Q1 = data[columna].quantile(0.25)\n",
    "    Q3 = data[columna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[columna] < limite_inferior) | (data[columna] > limite_superior)]\n",
    "    return outliers, limite_inferior, limite_superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers_zscore(data, columna, umbral=3):\n",
    "    # principalmente para casos donde la distribucion es normal\n",
    "    from scipy import stats\n",
    "    z_scores = np.abs(stats.zscore(data[columna].dropna()))\n",
    "    outliers_indices = np.where(z_scores > umbral)[0]\n",
    "    outliers = data.iloc[outliers_indices]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5130ba",
   "metadata": {},
   "source": [
    "_La distancia de Mahalanobis se usa para detectar outliers multivariados porque mide la distancia de un punto a la media de una distribución, pero también considera la correlación entre las variables. Esto la hace más precisa que la distancia euclidiana, ya que un punto puede estar lejos de la media en un solo eje pero no ser un outlier si sigue la tendencia de las variables correlacionadas, y viceversa. Un valor de distancia de Mahalanobis alto indica un outlier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers_mahalanobis(df, columnas, umbral=3):\n",
    "    from scipy.spatial.distance import mahalanobis\n",
    "    from scipy.linalg import inv\n",
    "    \n",
    "    data = df[columnas].dropna()\n",
    "    cov_matrix = np.cov(data, rowvar=False)\n",
    "    inv_cov_matrix = inv(cov_matrix)\n",
    "    media = np.mean(data, axis=0)\n",
    "    \n",
    "    distancias = []\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            dist = mahalanobis(data.iloc[i], media, inv_cov_matrix)\n",
    "            distancias.append(dist)\n",
    "        except:\n",
    "            distancias.append(0)\n",
    "    \n",
    "    outliers = data[np.array(distancias) > umbral]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def analisis_completo_outliers(df, columna):\n",
    "    \"\"\"Análisis completo de outliers para una columna\"\"\"\n",
    "    \n",
    "    data = df[columna].dropna()\n",
    "    \n",
    "    # Método IQR\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lim_inf_iqr = Q1 - 1.5 * IQR\n",
    "    lim_sup_iqr = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Método Z-Score\n",
    "    z_scores = np.abs(stats.zscore(data))\n",
    "    lim_sup_zscore = 3\n",
    "    \n",
    "    # Identificar outliers\n",
    "    outliers_iqr = data[(data < lim_inf_iqr) | (data > lim_sup_iqr)]\n",
    "    outliers_zscore = data[z_scores > lim_sup_zscore]\n",
    "    \n",
    "    # Estadísticas\n",
    "    stats_dict = {\n",
    "        'columna': columna,\n",
    "        'n_total': len(data),\n",
    "        'n_outliers_iqr': len(outliers_iqr),\n",
    "        'n_outliers_zscore': len(outliers_zscore),\n",
    "        'pct_outliers_iqr': (len(outliers_iqr) / len(data)) * 100,\n",
    "        'pct_outliers_zscore': (len(outliers_zscore) / len(data)) * 100,\n",
    "        'lim_inf_iqr': lim_inf_iqr,\n",
    "        'lim_sup_iqr': lim_sup_iqr,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'mediana': np.median(data)\n",
    "    }\n",
    "    \n",
    "    return stats_dict, outliers_iqr, outliers_zscore\n",
    "\n",
    "# Aplicar a todas las columnas numéricas\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "resultados_outliers = {}\n",
    "print(\" ANÁLISIS DE OUTLIERS \")\n",
    "\n",
    "for col in numeric_columns:\n",
    "    stats_dict, outliers_iqr, outliers_zscore = analisis_completo_outliers(df, col)\n",
    "    resultados_outliers[col] = {\n",
    "        'stats': stats_dict,\n",
    "        'outliers_iqr': outliers_iqr,\n",
    "        'outliers_zscore': outliers_zscore\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"   • Outliers IQR: {stats_dict['n_outliers_iqr']} ({stats_dict['pct_outliers_iqr']:.1f}%)\")\n",
    "    print(f\"   • Outliers Z-Score: {stats_dict['n_outliers_zscore']} ({stats_dict['pct_outliers_zscore']:.1f}%)\")\n",
    "    print(f\"   • Límites IQR: [{stats_dict['lim_inf_iqr']:.2f}, {stats_dict['lim_sup_iqr']:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17093698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_outliers(df, col):\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    # Calcular estadísticas si no existen en resultados_outliers\n",
    "    if col not in resultados_outliers:\n",
    "        stats_dict, _, _ = analisis_completo_outliers(df, col)\n",
    "    else:\n",
    "        stats_dict = resultados_outliers[col]['stats']\n",
    "    \n",
    "    # Crear figura con subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. BOXPLOT\n",
    "    axes[0, 0].boxplot(data, vert=True)\n",
    "    axes[0, 0].set_title(f'Boxplot - {col}')\n",
    "    axes[0, 0].set_ylabel('Valor')\n",
    "    \n",
    "    # Añadir líneas de referencia\n",
    "    axes[0, 0].axhline(y=stats_dict['lim_sup_iqr'], color='r', linestyle='--', \n",
    "                      alpha=0.7, label=f'Lím Sup: {stats_dict[\"lim_sup_iqr\"]:.2f}')\n",
    "    axes[0, 0].axhline(y=stats_dict['lim_inf_iqr'], color='r', linestyle='--', \n",
    "                      alpha=0.7, label=f'Lím Inf: {stats_dict[\"lim_inf_iqr\"]:.2f}')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. HISTOGRAMA con outliers destacados\n",
    "    n, bins, patches = axes[0, 1].hist(data, bins=30, alpha=0.7, color='skyblue', \n",
    "                                      edgecolor='black')\n",
    "    \n",
    "    # Colorear outliers en rojo\n",
    "    for j in range(len(bins)-1):\n",
    "        bin_center = (bins[j] + bins[j+1]) / 2\n",
    "        if bin_center > stats_dict['lim_sup_iqr'] or bin_center < stats_dict['lim_inf_iqr']:\n",
    "            patches[j].set_facecolor('red')\n",
    "            patches[j].set_alpha(0.8)\n",
    "    \n",
    "    axes[0, 1].axvline(stats_dict['lim_sup_iqr'], color='r', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].axvline(stats_dict['lim_inf_iqr'], color='r', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].set_title(f'Histograma - {col}')\n",
    "    axes[0, 1].set_xlabel('Valor')\n",
    "    axes[0, 1].set_ylabel('Frecuencia')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. SCATTER PLOT con outliers\n",
    "    outliers_mask = (data < stats_dict['lim_inf_iqr']) | (data > stats_dict['lim_sup_iqr'])\n",
    "    axes[1, 0].scatter(range(len(data)), data, alpha=0.6, \n",
    "                      c=outliers_mask, cmap='coolwarm', s=50)\n",
    "    axes[1, 0].axhline(y=stats_dict['lim_sup_iqr'], color='r', linestyle='--', alpha=0.7)\n",
    "    axes[1, 0].axhline(y=stats_dict['lim_inf_iqr'], color='r', linestyle='--', alpha=0.7)\n",
    "    axes[1, 0].set_title(f'Scatter Plot - {col}')\n",
    "    axes[1, 0].set_xlabel('Índice')\n",
    "    axes[1, 0].set_ylabel('Valor')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. VIOLIN PLOT\n",
    "    axes[1, 1].violinplot(data, showmeans=True, showmedians=True)\n",
    "    axes[1, 1].set_title(f'Violin Plot - {col}')\n",
    "    axes[1, 1].set_ylabel('Valor')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Añadir líneas en violin plot también\n",
    "    axes[1, 1].axhline(y=stats_dict['lim_sup_iqr'], color='r', linestyle='--', alpha=0.7)\n",
    "    axes[1, 1].axhline(y=stats_dict['lim_inf_iqr'], color='r', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar estadísticas\n",
    "    print(f\"\\n📊 ESTADÍSTICAS - {col}:\")\n",
    "    print(f\"   • Total observaciones: {stats_dict['n_total']}\")\n",
    "    print(f\"   • Outliers detectados: {stats_dict['n_outliers_iqr']} ({stats_dict['pct_outliers_iqr']:.1f}%)\")\n",
    "    print(f\"   • Límites IQR: [{stats_dict['lim_inf_iqr']:.2f}, {stats_dict['lim_sup_iqr']:.2f}]\")\n",
    "    print(f\"   • Rango IQR: [{stats_dict['Q1']:.2f}, {stats_dict['Q3']:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46926bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "    viz_outliers(df, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55e620",
   "metadata": {},
   "source": [
    "Tecnicas para \"Remover outliers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119f531",
   "metadata": {},
   "source": [
    "- Winsorizing: Reemplazar outliers con percentiles específicos\n",
    "\n",
    "- Capping: Limitar valores a umbrales definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_winsorizing(data, limites=(0.05, 0.95)):\n",
    "    \"\"\"Aplica winsorizing a los datos\"\"\"\n",
    "\n",
    "    lim_inferior, lim_superior = limites\n",
    "\n",
    "    inferior = np.percentile(data, lim_inferior * 100)\n",
    "    superior = np.percentile(data, lim_superior * 100)\n",
    "    \n",
    "    \n",
    "    return np.clip(data, inferior, superior)\n",
    "\n",
    "def aplicar_capping(data, metodo='iqr', factor=1.5):\n",
    "    \"\"\"Aplica capping (recorte de valores extremos) usando diferentes métodos.\"\"\"\n",
    "    \n",
    "    if metodo == 'iqr':\n",
    "        Q1, Q3 = np.percentile(data, [25, 75])\n",
    "        IQR = Q3 - Q1\n",
    "        lim_inf = Q1 - factor * IQR\n",
    "        lim_sup = Q3 + factor * IQR\n",
    "\n",
    "    elif metodo == 'percentile':\n",
    "        lim_inf, lim_sup = np.percentile(data, [1, 99])\n",
    "\n",
    "    elif metodo == 'zscore':\n",
    "        media, std = np.mean(data), np.std(data)\n",
    "        lim_inf = media - 3 * std\n",
    "        lim_sup = media + 3 * std\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Método '{metodo}' no reconocido. Usa: 'iqr', 'percentile' o 'zscore'.\")\n",
    "\n",
    "    # Aplicar límites de forma vectorizada y eficiente\n",
    "    data_capped = np.clip(data, lim_inf, lim_sup)\n",
    "\n",
    "    return data_capped, lim_inf, lim_sup\n",
    "\n",
    "\n",
    "# Comparación de métodos\n",
    "def comparar_tecnicas_outliers(df, columna):\n",
    "    \"\"\"Compara diferentes técnicas de tratamiento de outliers\"\"\"\n",
    "    \n",
    "    original = df[columna].dropna()\n",
    "    \n",
    "    # Aplicar diferentes técnicas\n",
    "    winsorized = aplicar_winsorizing(original)\n",
    "    capped_iqr, lim_inf_iqr, lim_sup_iqr = aplicar_capping(original, 'iqr')\n",
    "    capped_percentile, lim_inf_perc, lim_sup_perc = aplicar_capping(original, 'percentile')\n",
    "    \n",
    "    # Crear DataFrame comparativo\n",
    "    comparacion = pd.DataFrame({\n",
    "        'original': original,\n",
    "        'winsorized': winsorized,\n",
    "        'capped_iqr': capped_iqr,\n",
    "        'capped_percentile': capped_percentile\n",
    "    })\n",
    "    \n",
    "    return comparacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_columns:\n",
    "    # Aplicar a una columna de ejemplo\n",
    "    comparacion = comparar_tecnicas_outliers(df, col)\n",
    "\n",
    "    print(\" COMPARACIÓN DE TÉCNICAS \")\n",
    "    print(f\"Columna: {col}\")\n",
    "    print(\"\\nEstadísticas descriptivas:\")\n",
    "    print(comparacion.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc4eb46",
   "metadata": {},
   "source": [
    "# ** Guía Teórica: Cuándo Usar Winsorizing vs IQR vs Percentile**\n",
    "\n",
    "## ** Comparativa Conceptual**\n",
    "\n",
    "| Método | Concepto | Robustez | Preservación Datos | Casos Ideales |\n",
    "|--------|----------|-----------|-------------------|---------------|\n",
    "| **Winsorizing** | Reemplaza extremos con percentiles | Media | Alta | Datos con colas pesadas |\n",
    "| **IQR (Capping)** | Corta valores beyond ±1.5×IQR | Alta | Media | Distribuciones simétricas |\n",
    "| **Percentile** | Corta en percentiles fijos | Media | Baja | Conocimiento del dominio |\n",
    "\n",
    "---\n",
    "\n",
    "## ** WINSORIZING - Cuándo Usar**\n",
    "\n",
    "### **Casos Ideales:**\n",
    "# Ejemplos donde WINSORIZING es mejor:\n",
    "\n",
    "-  Datos financieros (retornos, precios)\n",
    "    * \"Retornos de acciones: -10%, 2%, 1%, 15%, -8%, 25%, -50%\"\n",
    "    * \"→ Winsorizing (5%, 95%) preserva la volatilidad pero controla extremos\"\n",
    "\n",
    "-  Mediciones médicas (valores biológicos)\n",
    "    * \"Presión arterial: 120, 118, 122, 180, 115, 200, 110\"\n",
    "    * \"→ Los extremos pueden ser reales pero raros - winsorizing los suaviza\"\n",
    "\n",
    "-  Cuando importa la forma de la distribución\n",
    "    * \"Análisis de distribución de ingresos\"\n",
    "    * \"→ Winsorizing mantiene la forma general mientras controla outliers\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04301980",
   "metadata": {},
   "source": [
    "# **Guía Teórica: Cuándo Usar Winsorizing vs IQR vs Percentile**\n",
    "\n",
    "## **WINSORIZING - Cuándo Usar**\n",
    "\n",
    "### **Casos Ideales:**\n",
    "\n",
    "**1. Datos con colas pesadas o distribuciones asimétricas**\n",
    "- Cuando los outliers son valores reales pero extremos\n",
    "- Ejemplo: ingresos, precios de activos financieros, mediciones biológicas\n",
    "- Preserva la forma de la distribución mientras controla valores extremos\n",
    "\n",
    "**2. Cuando se necesita mantener el tamaño de la muestra**\n",
    "- No reduce el número de observaciones\n",
    "- Reemplaza valores extremos en lugar de eliminarlos\n",
    "- Importante en muestras pequeñas o análisis estadísticos que requieren n constante\n",
    "\n",
    "**3. Análisis donde la varianza es importante**\n",
    "- Mantiene mejor la variabilidad original que el capping\n",
    "- Ideal para análisis paramétricos posteriores\n",
    "\n",
    "**4. Cuando los valores extremos contienen información valiosa**\n",
    "- Los outliers son casos raros pero legítimos\n",
    "- Ejemplo: pacientes con respuestas excepcionales a tratamientos\n",
    "\n",
    "---\n",
    "\n",
    "## **IQR (Capping) - Cuándo Usar**\n",
    "\n",
    "### **Casos Ideales:**\n",
    "\n",
    "**1. Distribuciones aproximadamente normales o simétricas**\n",
    "- Cuando los datos siguen una distribución en forma de campana\n",
    "- El método IQR asume cierta simetría en los datos\n",
    "\n",
    "**2. Outliers claramente erróneos o irrelevantes**\n",
    "- Errores de medición, entrada de datos o instrumentación\n",
    "- Valores que no representan el fenómeno de interés\n",
    "- Ejemplo: edad registrada como 200 años\n",
    "\n",
    "**3. Control de calidad y procesos industriales**\n",
    "- Cuando existen límites de especificación conocidos\n",
    "- Valores fuera de rangos fisiológicos o operativos aceptables\n",
    "\n",
    "**4. Preparación de datos para machine learning**\n",
    "- Algoritmos sensibles a valores extremos\n",
    "- Modelos que asumen distribución normal o rangos acotados\n",
    "\n",
    "**5. Cuando se busca un método estandarizado y ampliamente aceptado**\n",
    "- IQR es fácil de explicar y entender\n",
    "- Método robusto que no depende de supuestos de normalidad\n",
    "\n",
    "---\n",
    "\n",
    "## **MÉTODO POR PERCENTILE - Cuándo Usar**\n",
    "\n",
    "### **Casos Ideales:**\n",
    "\n",
    "**1. Conocimiento previo del dominio**\n",
    "- Cuando se sabe que valores beyond ciertos percentiles no son válidos\n",
    "- Ejemplo: en antropometría, estaturas beyond percentil 1% o 99% pueden ser errores\n",
    "\n",
    "**2. Datos con distribuciones muy irregulares**\n",
    "- Cuando IQR no funciona bien por asimetría extrema\n",
    "- Distribuciones multimodales o con gaps\n",
    "\n",
    "**3. Benchmarking contra estándares de la industria**\n",
    "- Cuando existen percentiles de referencia establecidos\n",
    "- Ejemplo: percentiles de crecimiento infantil, percentiles financieros\n",
    "\n",
    "**4. Cuando se requieren límites fijos y consistentes**\n",
    "- Los percentiles no cambian entre diferentes muestras de la misma población\n",
    "- Útil para comparaciones longitudinales\n",
    "\n",
    "---\n",
    "\n",
    "## **Comparación de Robustez**\n",
    "\n",
    "**Winsorizing:**\n",
    "- Menos distorsión de la distribución original\n",
    "- Mantiene mejor las propiedades estadísticas\n",
    "- Más suave con los valores extremos\n",
    "\n",
    "**IQR:**\n",
    "- Altamente robusto a outliers\n",
    "- No depende de la media ni desviación estándar\n",
    "- Funciona bien con distribuciones no normales\n",
    "\n",
    "**Percentile:**\n",
    "- Poco robusto con muestras pequeñas\n",
    "- Sensible a la elección arbitraria de percentiles\n",
    "- Puede eliminar datos válidos\n",
    "\n",
    "---\n",
    "\n",
    "## **Recomendaciones por Contexto**\n",
    "\n",
    "**Investigación Científica:**\n",
    "- Winsorizing para preservar información\n",
    "- IQR cuando los outliers son errores de medición\n",
    "\n",
    "**Finanzas y Economía:**\n",
    "- Winsorizing para mantener las colas de distribución\n",
    "- Percentiles para análisis de riesgo (VaR)\n",
    "\n",
    "**Machine Learning:**\n",
    "- IQR para la mayoría de casos\n",
    "- Winsorizing cuando los outliers contienen información predictiva\n",
    "\n",
    "**Control de Calidad:**\n",
    "- IQR o percentiles basados en especificaciones\n",
    "- Límites definidos por el proceso\n",
    "\n",
    "---\n",
    "\n",
    "## **Consideraciones Prácticas**\n",
    "\n",
    "**Tamaño de Muestra:**\n",
    "- Muestras pequeñas: Winsorizing o IQR\n",
    "- Muestras grandes: Cualquier método funciona bien\n",
    "\n",
    "**Propósito del Análisis:**\n",
    "- Análisis exploratorio: Probar múltiples métodos\n",
    "- Análisis inferencial: Winsorizing suave\n",
    "- Modelado predictivo: IQR o eliminación\n",
    "\n",
    "**Distribución de los Datos:**\n",
    "- Simétrica: IQR\n",
    "- Asimétrica: Winsorizing\n",
    "- Multimodal: Percentiles específicos por modo\n",
    "\n",
    "La elección depende fundamentalmente de si consideramos que los outliers representan información valiosa o deben ser tratados como anomalías a controlar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "86400_data_science_i_diplomatura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
