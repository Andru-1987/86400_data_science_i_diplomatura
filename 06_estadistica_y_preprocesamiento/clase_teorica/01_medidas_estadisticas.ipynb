{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40236a9b",
   "metadata": {},
   "source": [
    "\n",
    "## **Variables y tipos de datos**\n",
    "\n",
    "### **Noci√≥n de variable**\n",
    "\n",
    "Representa una caracter√≠stica medible de la unidad de observaci√≥n.\n",
    "Ejemplo: ‚Äúedad‚Äù, ‚Äúg√©nero‚Äù, ‚Äúnivel de ingresos‚Äù.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tipos de variables**\n",
    "\n",
    "| Tipo                              | Subtipo    | Ejemplo           | Observaciones                               |\n",
    "| --------------------------------- | ---------- | ----------------- | ------------------------------------------- |\n",
    "| **Cuantitativa**                  | *Discreta* | N¬∫ de hijos       | Solo enteros                                |\n",
    "|                                   | *Continua* | Peso, temperatura | Puede tener decimales                       |\n",
    "| **Cualitativa**                   | *Nominal*  | Color, pa√≠s       | Sin orden                                   |\n",
    "|                                   | *Ordinal*  | Nivel educativo   | Con jerarqu√≠a                               |\n",
    "| **L√≥gica**                        | ‚Äî          | Verdadero/Falso   | Muy usada en ML                             |\n",
    "| **Metadatos / Alta cardinalidad** | ‚Äî          | ID cliente        | Identificadores, no se modelan directamente |\n",
    "\n",
    "*En machine learning*: elegir bien el tipo de variable define el tipo de preprocesamiento (por ejemplo, normalizaci√≥n, codificaci√≥n, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Medidas de resumen**\n",
    "\n",
    "### 4.1. **Cuantitativas**\n",
    "\n",
    "| Medida                  | Qu√© mide                          | F√≥rmula o idea                          |\n",
    "| ----------------------- | --------------------------------- | --------------------------------------- |\n",
    "| **Media**               | Promedio                          | (Œ£x·µ¢)/n                                 |\n",
    "| **Mediana**             | Valor central                     | Divide el conjunto en dos mitades       |\n",
    "| **Moda**                | Valor m√°s frecuente               | Aplica tambi√©n a categor√≠as             |\n",
    "| **Varianza (s¬≤)**       | Dispersi√≥n cuadr√°tica             | Promedio de las diferencias al cuadrado |\n",
    "| **Desv√≠o est√°ndar (s)** | Dispersi√≥n en unidades originales | ‚àövarianza                               |\n",
    "\n",
    "*Interpretaci√≥n*:\n",
    "Si dos variables tienen igual media pero distinta desviaci√≥n est√°ndar, una es m√°s ‚Äúvariable‚Äù o dispersa que la otra.\n",
    "\n",
    "---\n",
    "\n",
    "### **Cualitativas**\n",
    "\n",
    "Solo se analizan **frecuencias o proporciones**.\n",
    "Medidas de tendencia central\n",
    "    *Moda*: Es la categor√≠a que aparece con mayor frecuencia en el conjunto de datos. Esta es la √∫nica medida de tendencia central que se puede usar para datos cualitativos nominales. \n",
    "    *Mediana*: Solo se puede calcular para datos cualitativos de tipo ordinal (que se pueden ordenar). \n",
    "Ejemplo:\n",
    "\n",
    "| Categor√≠a | Frecuencia | Porcentaje |\n",
    "| --------- | ---------- | ---------- |\n",
    "| Masculino | 60         | 60%        |\n",
    "| Femenino  | 40         | 40%        |\n",
    "\n",
    "La **moda categ√≥rica** es la categor√≠a m√°s com√∫n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8186c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef770212",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/Andru-1987/csv_files_ds/refs/heads/main/glasdoordata.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df = df.assign(\n",
    "    performance=df[\"performance\"].astype(\"category\"),\n",
    "    seniority=df[\"seniority\"].astype(\"category\")\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04246ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\nColumnas num√©ricas: {list(numeric_columns)}\")\n",
    "\n",
    "# Calcular varianza y desviaci√≥n est√°ndar para cada columna num√©rica\n",
    "print(\"\\n VARIANZA Y DESVIACI√ìN EST√ÅNDAR\")\n",
    "results = {}\n",
    "\n",
    "for col in numeric_columns:\n",
    "    # Eliminar valores NaN para el c√°lculo\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    # C√°lculos manuales\n",
    "    media = np.mean(data)\n",
    "    n = len(data)\n",
    "    \n",
    "    # Varianza poblacional (dividiendo por N)\n",
    "    varianza_poblacional = np.sum((data - media)**2) / n\n",
    "    \n",
    "    # Varianza muestral (dividiendo por n-1)\n",
    "    varianza_muestral = np.sum((data - media)**2) / (n - 1)\n",
    "    \n",
    "    # Desviaci√≥n est√°ndar\n",
    "    desv_std_poblacional = np.sqrt(varianza_poblacional)\n",
    "    desv_std_muestral = np.sqrt(varianza_muestral)\n",
    "    \n",
    "    # Usando funciones de numpy (para verificaci√≥n)\n",
    "    var_numpy = np.var(data, ddof=1)  # ddof=1 para muestra, ddof=0 para poblaci√≥n\n",
    "    std_numpy = np.std(data, ddof=1)\n",
    "    \n",
    "    results[col] = {\n",
    "        'media': media,\n",
    "        'varianza_poblacional': varianza_poblacional,\n",
    "        'varianza_muestral': varianza_muestral,\n",
    "        'desv_std_poblacional': desv_std_poblacional,\n",
    "        'desv_std_muestral': desv_std_muestral,\n",
    "        'n': n\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(f\"Muestra (n): {n}\")\n",
    "    print(f\"Media: {media:.2f}\")\n",
    "    print(f\"Varianza (poblacional): {varianza_poblacional:.2f}\")\n",
    "    print(f\"Varianza (muestral): {varianza_muestral:.2f}\")\n",
    "    print(f\"Desviaci√≥n est√°ndar (poblacional): {desv_std_poblacional:.2f}\")\n",
    "    print(f\"Desviaci√≥n est√°ndar (muestral): {desv_std_muestral:.2f}\")\n",
    "    print(f\"Verificaci√≥n con numpy - Varianza: {var_numpy:.2f}\")\n",
    "    print(f\"Verificaci√≥n con numpy - Desv. std: {std_numpy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_desviacion(df:pd.DataFrame, column:str):\n",
    "    \n",
    "    data = df[column].dropna()\n",
    "    media = results[column]['media']\n",
    "    desv_std = results[column]['desv_std_muestral']\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Histograma\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(data, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(media, color='red', linestyle='--', linewidth=2, label=f'Media: {media:.2f}')\n",
    "    plt.axvline(media + desv_std, color='orange', linestyle='--', linewidth=2, label=f'¬±1œÉ')\n",
    "    plt.axvline(media - desv_std, color='orange', linestyle='--', linewidth=2)\n",
    "    plt.axvline(media + 2*desv_std, color='green', linestyle='--', linewidth=1, label=f'¬±2œÉ')\n",
    "    plt.axvline(media - 2*desv_std, color='green', linestyle='--', linewidth=1)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title(f'Distribuci√≥n de {column}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(data)\n",
    "    plt.ylabel(column)\n",
    "    plt.title(f'Boxplot de {column}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "    display_desviacion(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9068869",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESUMEN COMPARATIVO\")\n",
    "resumen_data = []\n",
    "for col in numeric_columns:\n",
    "    media = results[col]['media']\n",
    "    varianza = results[col]['varianza_muestral']\n",
    "    desv_std = results[col]['desv_std_muestral']\n",
    "    coef_variacion = (desv_std / media) * 100 if media != 0 else float('inf')\n",
    "    \n",
    "    resumen_data.append({\n",
    "        'Columna': col,\n",
    "        'Media': media,\n",
    "        'Varianza': varianza,\n",
    "        'Desv_Std': desv_std,\n",
    "        'Coef_Variacion_%': coef_variacion,\n",
    "        'n': results[col]['n']\n",
    "    })\n",
    "\n",
    "# Crear DataFrame\n",
    "resumen_df = pd.DataFrame(resumen_data)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(resumen_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127c445",
   "metadata": {},
   "source": [
    "Mide la variabilidad relativa de los datos en comparaci√≥n con su tama√±o promedio. A diferencia de la desviaci√≥n est√°ndar (que es una medida absoluta), el CV permite comparar la variabilidad entre diferentes conjuntos de datos, incluso si tienen:\n",
    "\n",
    "* Diferentes unidades de medida\n",
    "* Diferentes escalas\n",
    "* Diferentes magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a48e69",
   "metadata": {},
   "source": [
    "```sh\n",
    "CV < 15%    ‚Üí BAJA variabilidad (datos muy consistentes)\n",
    "15% ‚â§ CV < 30% ‚Üí MODERADA variabilidad  \n",
    "CV ‚â• 30%    ‚Üí ALTA variabilidad (datos muy dispersos)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80153264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n DATAFRAME CON AN√ÅLISIS INTERPRETATIVO \")\n",
    "\n",
    "analisis_df = pd.DataFrame({\n",
    "    'Columna': numeric_columns,\n",
    "    'Media': [results[col]['media'] for col in numeric_columns],\n",
    "    'Varianza': [results[col]['varianza_muestral'] for col in numeric_columns],\n",
    "    'Desv_Std': [results[col]['desv_std_muestral'] for col in numeric_columns],\n",
    "    'CV_%': [(results[col]['desv_std_muestral'] / results[col]['media']) * 100 \n",
    "             if results[col]['media'] != 0 else float('inf') \n",
    "             for col in numeric_columns],\n",
    "    'Rango_68%_Inferior': [results[col]['media'] - results[col]['desv_std_muestral'] \n",
    "                          for col in numeric_columns],\n",
    "    'Rango_68%_Superior': [results[col]['media'] + results[col]['desv_std_muestral'] \n",
    "                          for col in numeric_columns],\n",
    "    'Interpretacion_CV': [\n",
    "        \"BAJA variabilidad\" if ((results[col]['desv_std_muestral'] / results[col]['media']) * 100) < 15 \n",
    "        else \"MODERADA variabilidad\" if ((results[col]['desv_std_muestral'] / results[col]['media']) * 100) < 30 \n",
    "        else \"ALTA variabilidad\" \n",
    "        for col in numeric_columns\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Formatear el DataFrame\n",
    "analisis_df_formateado = analisis_df.round({\n",
    "    'Media': 2,\n",
    "    'Varianza': 2,\n",
    "    'Desv_Std': 2,\n",
    "    'CV_%': 1,\n",
    "    'Rango_68%_Inferior': 2,\n",
    "    'Rango_68%_Superior': 2\n",
    "})\n",
    "\n",
    "print(analisis_df_formateado.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ceb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESUMEN FINAL - MEDIDAS DE VARIABILIDAD\")\n",
    "\n",
    "styled_df = (analisis_df_formateado.style\n",
    "    .format({\n",
    "        'Media': '{:.2f}',\n",
    "        'Varianza': '{:.2f}', \n",
    "        'Desv_Std': '{:.2f}',\n",
    "        'CV_%': '{:.1f}%',\n",
    "        'Rango_68%_Inferior': '{:.2f}',\n",
    "        'Rango_68%_Superior': '{:.2f}'\n",
    "    })\n",
    "    .background_gradient(subset=['Varianza'], cmap='Reds')\n",
    "    .background_gradient(subset=['Desv_Std'], cmap='Blues')\n",
    "    .background_gradient(subset=['CV_%'], cmap='viridis')\n",
    "    )\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c246a6",
   "metadata": {},
   "source": [
    "## Intervalos de confianza\n",
    "\n",
    "Los intervalos de confianza permiten estimar un rango donde se encuentra un par√°metro poblacional con un cierto nivel de confianza.\n",
    "Los IC nos permiten expresar no solo una estimaci√≥n puntual, sino tambi√©n el margen de error de esa estimaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b75de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_intervalo_confianza(data, confianza=0.95):\n",
    "    n = len(data)\n",
    "    media = np.mean(data)\n",
    "    desv_std = np.std(data, ddof=1)  # Muestral\n",
    "    \n",
    "    # Valor cr√≠tico t (usamos t-student para muestras peque√±as, normal para grandes)\n",
    "    if n < 30:\n",
    "        valor_critico = stats.t.ppf((1 + confianza) / 2, n-1)\n",
    "    else:\n",
    "        valor_critico = stats.norm.ppf((1 + confianza) / 2)\n",
    "    \n",
    "    # Error est√°ndar\n",
    "    error_estandar = desv_std / np.sqrt(n)\n",
    "    \n",
    "    # Margen de error\n",
    "    margen_error = valor_critico * error_estandar\n",
    "    \n",
    "    # Intervalo de confianza\n",
    "    ic_inferior = media - margen_error\n",
    "    ic_superior = media + margen_error\n",
    "    \n",
    "    return {\n",
    "        'media': media,\n",
    "        'n': n,\n",
    "        'desv_std': desv_std,\n",
    "        'error_estandar': error_estandar,\n",
    "        'margen_error': margen_error,\n",
    "        'ic_inferior': ic_inferior,\n",
    "        'ic_superior': ic_superior,\n",
    "        'valor_critico': valor_critico,\n",
    "        'confianza': confianza\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular IC para cada columna num√©rica\n",
    "resultados_ic = {}\n",
    "niveles_confianza = [0.90, 0.95, 0.99]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    data = df[col].dropna()\n",
    "    resultados_ic[col] = {}\n",
    "    \n",
    "    for confianza in niveles_confianza:\n",
    "        resultados_ic[col][confianza] = calcular_intervalo_confianza(data, confianza)\n",
    "\n",
    "# Mostrar resultados en tabla\n",
    "print(\"TABLA DE INTERVALOS DE CONFIANZA\")\n",
    "\n",
    "tabla_ic = []\n",
    "for col in numeric_columns:\n",
    "    for confianza in niveles_confianza:\n",
    "        ic = resultados_ic[col][confianza]\n",
    "        tabla_ic.append({\n",
    "            'Variable': col,\n",
    "            'Confianza': f\"{confianza*100:.0f}%\",\n",
    "            'Media': ic['media'],\n",
    "            'IC_Inferior': ic['ic_inferior'],\n",
    "            'IC_Superior': ic['ic_superior'],\n",
    "            'Margen_Error': ic['margen_error'],\n",
    "            'n': ic['n']\n",
    "        })\n",
    "\n",
    "df_ic = pd.DataFrame(tabla_ic)\n",
    "print(df_ic.round(2).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b383dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparacion_niveles_confianza(df,column):\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    confianzas = [0.90, 0.95, 0.99]\n",
    "    colores = ['lightblue', 'blue', 'darkblue']\n",
    "    anchos = [0.6, 0.8, 1.0]\n",
    "\n",
    "    for i, confianza in enumerate(confianzas):\n",
    "        ic = resultados_ic[column][confianza]\n",
    "        \n",
    "        plt.hlines(y=len(confianzas)-i, xmin=ic['ic_inferior'], xmax=ic['ic_superior'], \n",
    "                color=colores[i], linewidth=5, label=f'{confianza*100:.0f}% Confianza')\n",
    "        plt.plot(ic['media'], len(confianzas)-i, 'ro', markersize=8)\n",
    "\n",
    "    plt.axvline(x=resultados_ic[column][0.95]['media'], color='red', linestyle='--', alpha=0.7, label='Media')\n",
    "    plt.xlabel('Valor')\n",
    "    plt.ylabel('Nivel de Confianza')\n",
    "    plt.title(f'Intervalos de Confianza para {column} - Diferentes Niveles')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.yticks([1, 2, 3], ['99%', '95%', '90%'])\n",
    "\n",
    "    # A√±adir valores\n",
    "    for i, confianza in enumerate(confianzas):\n",
    "        ic = resultados_ic[column][confianza]\n",
    "        plt.text(ic['ic_inferior'], len(confianzas)-i + 0.1, f'{ic[\"ic_inferior\"]:.1f}', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "        plt.text(ic['ic_superior'], len(confianzas)-i + 0.1, f'{ic[\"ic_superior\"]:.1f}', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "    comparacion_niveles_confianza(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INTERPRETACI√ìN PR√ÅCTICA DE LOS INTERVALOS DE CONFIANZA\")\n",
    "\n",
    "\n",
    "for col in numeric_columns:\n",
    "    ic_95 = resultados_ic[col][0.95]\n",
    "    \n",
    "    print(f\"\\n {col.upper()}:\")\n",
    "    print(f\"   ‚Ä¢ Con 95% de confianza, el valor real poblacional est√° entre:\")\n",
    "    print(f\"     {ic_95['ic_inferior']:.2f} y {ic_95['ic_superior']:.2f}\")\n",
    "    print(f\"   ‚Ä¢ Margen de error: ¬±{ic_95['margen_error']:.2f}\")\n",
    "    print(f\"   ‚Ä¢ Precisi√≥n: {ic_95['margen_error']/ic_95['media']*100:.1f}% de la media\")\n",
    "    \n",
    "    # Interpretaci√≥n de precisi√≥n\n",
    "    precision = (ic_95['margen_error'] / ic_95['media']) * 100\n",
    "    if precision < 5:\n",
    "        calidad = \"EXCELENTE precisi√≥n\"\n",
    "    elif precision < 10:\n",
    "        calidad = \"BUENA precisi√≥n\"\n",
    "    elif precision < 20:\n",
    "        calidad = \"PRECISI√ìN MODERADA\"\n",
    "    else:\n",
    "        calidad = \"BAJA precisi√≥n\"\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Calidad de estimaci√≥n: {calidad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75b325",
   "metadata": {},
   "source": [
    "### Deteccion de Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f482a0",
   "metadata": {},
   "source": [
    "El m√©todo del Rango Intercuart√≠lico (IQR) se usa para identificar valores at√≠picos (\\(outliers\\)) en un conjunto de datos, especialmente cuando no hay una distribuci√≥n normal. Sirve para encontrar valores que est√°n inusualmente altos o bajos en comparaci√≥n con el resto de los datos, y es robusto porque no se ve afectado por valores extremos. Tambi√©n se utiliza para entender la dispersi√≥n de la mitad central de los datos y como una medida de variabilidad junto con la mediana\n",
    "\n",
    "_El m√©todo intercuartil (RIC) para la detecci√≥n de valores at√≠picos utiliza una escala de 1,5 para detectarlos , ya que se ajusta con mayor precisi√≥n a la distribuci√≥n gaussiana . Por lo tanto, el m√©todo determina que cualquier punto de datos que se encuentre 1,5 puntos por debajo del cuartil inferior o por encima del cuartil superior es un valor at√≠pico._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ab258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers_iqr(data, columna):\n",
    "    Q1 = data[columna].quantile(0.25)\n",
    "    Q3 = data[columna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[columna] < limite_inferior) | (data[columna] > limite_superior)]\n",
    "    return outliers, limite_inferior, limite_superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers_zscore(data, columna, umbral=3):\n",
    "    # principalmente para casos donde la distribucion es normal\n",
    "    from scipy import stats\n",
    "    z_scores = np.abs(stats.zscore(data[columna].dropna()))\n",
    "    outliers_indices = np.where(z_scores > umbral)[0]\n",
    "    outliers = data.iloc[outliers_indices]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5130ba",
   "metadata": {},
   "source": [
    "_La distancia de Mahalanobis se usa para detectar outliers multivariados porque mide la distancia de un punto a la media de una distribuci√≥n, pero tambi√©n considera la correlaci√≥n entre las variables. Esto la hace m√°s precisa que la distancia euclidiana, ya que un punto puede estar lejos de la media en un solo eje pero no ser un outlier si sigue la tendencia de las variables correlacionadas, y viceversa. Un valor de distancia de Mahalanobis alto indica un outlier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers_mahalanobis(df, columnas, umbral=3):\n",
    "    from scipy.spatial.distance import mahalanobis\n",
    "    from scipy.linalg import inv\n",
    "    \n",
    "    data = df[columnas].dropna()\n",
    "    cov_matrix = np.cov(data, rowvar=False)\n",
    "    inv_cov_matrix = inv(cov_matrix)\n",
    "    media = np.mean(data, axis=0)\n",
    "    \n",
    "    distancias = []\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            dist = mahalanobis(data.iloc[i], media, inv_cov_matrix)\n",
    "            distancias.append(dist)\n",
    "        except:\n",
    "            distancias.append(0)\n",
    "    \n",
    "    outliers = data[np.array(distancias) > umbral]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def analisis_completo_outliers(df, columna):\n",
    "    \"\"\"An√°lisis completo de outliers para una columna\"\"\"\n",
    "    \n",
    "    data = df[columna].dropna()\n",
    "    \n",
    "    # M√©todo IQR\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lim_inf_iqr = Q1 - 1.5 * IQR\n",
    "    lim_sup_iqr = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # M√©todo Z-Score\n",
    "    z_scores = np.abs(stats.zscore(data))\n",
    "    lim_sup_zscore = 3\n",
    "    \n",
    "    # Identificar outliers\n",
    "    outliers_iqr = data[(data < lim_inf_iqr) | (data > lim_sup_iqr)]\n",
    "    outliers_zscore = data[z_scores > lim_sup_zscore]\n",
    "    \n",
    "    # Estad√≠sticas\n",
    "    stats_dict = {\n",
    "        'columna': columna,\n",
    "        'n_total': len(data),\n",
    "        'n_outliers_iqr': len(outliers_iqr),\n",
    "        'n_outliers_zscore': len(outliers_zscore),\n",
    "        'pct_outliers_iqr': (len(outliers_iqr) / len(data)) * 100,\n",
    "        'pct_outliers_zscore': (len(outliers_zscore) / len(data)) * 100,\n",
    "        'lim_inf_iqr': lim_inf_iqr,\n",
    "        'lim_sup_iqr': lim_sup_iqr,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'mediana': np.median(data)\n",
    "    }\n",
    "    \n",
    "    return stats_dict, outliers_iqr, outliers_zscore\n",
    "\n",
    "# Aplicar a todas las columnas num√©ricas\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "resultados_outliers = {}\n",
    "print(\" AN√ÅLISIS DE OUTLIERS \")\n",
    "\n",
    "for col in numeric_columns:\n",
    "    stats_dict, outliers_iqr, outliers_zscore = analisis_completo_outliers(df, col)\n",
    "    resultados_outliers[col] = {\n",
    "        'stats': stats_dict,\n",
    "        'outliers_iqr': outliers_iqr,\n",
    "        'outliers_zscore': outliers_zscore\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"   ‚Ä¢ Outliers IQR: {stats_dict['n_outliers_iqr']} ({stats_dict['pct_outliers_iqr']:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Outliers Z-Score: {stats_dict['n_outliers_zscore']} ({stats_dict['pct_outliers_zscore']:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ L√≠mites IQR: [{stats_dict['lim_inf_iqr']:.2f}, {stats_dict['lim_sup_iqr']:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17093698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_outliers(df, col):\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    # Calcular estad√≠sticas si no existen en resultados_outliers\n",
    "    if col not in resultados_outliers:\n",
    "        stats_dict, _, _ = analisis_completo_outliers(df, col)\n",
    "    else:\n",
    "        stats_dict = resultados_outliers[col]['stats']\n",
    "    \n",
    "    # Crear figura con subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. BOXPLOT\n",
    "    axes[0, 0].boxplot(data, vert=True)\n",
    "    axes[0, 0].set_title(f'Boxplot - {col}')\n",
    "    axes[0, 0].set_ylabel('Valor')\n",
    "    \n",
    "    # A√±adir l√≠neas de referencia\n",
    "    axes[0, 0].axhline(y=stats_dict['lim_sup_iqr'], color='r', linestyle='--', \n",
    "                      alpha=0.7, label=f'L√≠m Sup: {stats_dict[\"lim_sup_iqr\"]:.2f}')\n",
    "    axes[0, 0].axhline(y=stats_dict['lim_inf_iqr'], color='r', linestyle='--', \n",
    "                      alpha=0.7, label=f'L√≠m Inf: {stats_dict[\"lim_inf_iqr\"]:.2f}')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. HISTOGRAMA con outliers destacados\n",
    "    n, bins, patches = axes[0, 1].hist(data, bins=30, alpha=0.7, color='skyblue', \n",
    "                                      edgecolor='black')\n",
    "    \n",
    "    # Colorear outliers en rojo\n",
    "    for j in range(len(bins)-1):\n",
    "        bin_center = (bins[j] + bins[j+1]) / 2\n",
    "        if bin_center > stats_dict['lim_sup_iqr'] or bin_center < stats_dict['lim_inf_iqr']:\n",
    "            patches[j].set_facecolor('red')\n",
    "            patches[j].set_alpha(0.8)\n",
    "    \n",
    "    axes[0, 1].axvline(stats_dict['lim_sup_iqr'], color='r', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].axvline(stats_dict['lim_inf_iqr'], color='r', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].set_title(f'Histograma - {col}')\n",
    "    axes[0, 1].set_xlabel('Valor')\n",
    "    axes[0, 1].set_ylabel('Frecuencia')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. SCATTER PLOT con outliers\n",
    "    outliers_mask = (data < stats_dict['lim_inf_iqr']) | (data > stats_dict['lim_sup_iqr'])\n",
    "    axes[1, 0].scatter(range(len(data)), data, alpha=0.6, \n",
    "                      c=outliers_mask, cmap='coolwarm', s=50)\n",
    "    axes[1, 0].axhline(y=stats_dict['lim_sup_iqr'], color='r', linestyle='--', alpha=0.7)\n",
    "    axes[1, 0].axhline(y=stats_dict['lim_inf_iqr'], color='r', linestyle='--', alpha=0.7)\n",
    "    axes[1, 0].set_title(f'Scatter Plot - {col}')\n",
    "    axes[1, 0].set_xlabel('√çndice')\n",
    "    axes[1, 0].set_ylabel('Valor')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. VIOLIN PLOT\n",
    "    axes[1, 1].violinplot(data, showmeans=True, showmedians=True)\n",
    "    axes[1, 1].set_title(f'Violin Plot - {col}')\n",
    "    axes[1, 1].set_ylabel('Valor')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # A√±adir l√≠neas en violin plot tambi√©n\n",
    "    axes[1, 1].axhline(y=stats_dict['lim_sup_iqr'], color='r', linestyle='--', alpha=0.7)\n",
    "    axes[1, 1].axhline(y=stats_dict['lim_inf_iqr'], color='r', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar estad√≠sticas\n",
    "    print(f\"\\nüìä ESTAD√çSTICAS - {col}:\")\n",
    "    print(f\"   ‚Ä¢ Total observaciones: {stats_dict['n_total']}\")\n",
    "    print(f\"   ‚Ä¢ Outliers detectados: {stats_dict['n_outliers_iqr']} ({stats_dict['pct_outliers_iqr']:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ L√≠mites IQR: [{stats_dict['lim_inf_iqr']:.2f}, {stats_dict['lim_sup_iqr']:.2f}]\")\n",
    "    print(f\"   ‚Ä¢ Rango IQR: [{stats_dict['Q1']:.2f}, {stats_dict['Q3']:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46926bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "    viz_outliers(df, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55e620",
   "metadata": {},
   "source": [
    "Tecnicas para \"Remover outliers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119f531",
   "metadata": {},
   "source": [
    "- Winsorizing: Reemplazar outliers con percentiles espec√≠ficos\n",
    "\n",
    "- Capping: Limitar valores a umbrales definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_winsorizing(data, limites=(0.05, 0.95)):\n",
    "    \"\"\"Aplica winsorizing a los datos\"\"\"\n",
    "\n",
    "    lim_inferior, lim_superior = limites\n",
    "\n",
    "    inferior = np.percentile(data, lim_inferior * 100)\n",
    "    superior = np.percentile(data, lim_superior * 100)\n",
    "    \n",
    "    \n",
    "    return np.clip(data, inferior, superior)\n",
    "\n",
    "def aplicar_capping(data, metodo='iqr', factor=1.5):\n",
    "    \"\"\"Aplica capping (recorte de valores extremos) usando diferentes m√©todos.\"\"\"\n",
    "    \n",
    "    if metodo == 'iqr':\n",
    "        Q1, Q3 = np.percentile(data, [25, 75])\n",
    "        IQR = Q3 - Q1\n",
    "        lim_inf = Q1 - factor * IQR\n",
    "        lim_sup = Q3 + factor * IQR\n",
    "\n",
    "    elif metodo == 'percentile':\n",
    "        lim_inf, lim_sup = np.percentile(data, [1, 99])\n",
    "\n",
    "    elif metodo == 'zscore':\n",
    "        media, std = np.mean(data), np.std(data)\n",
    "        lim_inf = media - 3 * std\n",
    "        lim_sup = media + 3 * std\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"M√©todo '{metodo}' no reconocido. Usa: 'iqr', 'percentile' o 'zscore'.\")\n",
    "\n",
    "    # Aplicar l√≠mites de forma vectorizada y eficiente\n",
    "    data_capped = np.clip(data, lim_inf, lim_sup)\n",
    "\n",
    "    return data_capped, lim_inf, lim_sup\n",
    "\n",
    "\n",
    "# Comparaci√≥n de m√©todos\n",
    "def comparar_tecnicas_outliers(df, columna):\n",
    "    \"\"\"Compara diferentes t√©cnicas de tratamiento de outliers\"\"\"\n",
    "    \n",
    "    original = df[columna].dropna()\n",
    "    \n",
    "    # Aplicar diferentes t√©cnicas\n",
    "    winsorized = aplicar_winsorizing(original)\n",
    "    capped_iqr, lim_inf_iqr, lim_sup_iqr = aplicar_capping(original, 'iqr')\n",
    "    capped_percentile, lim_inf_perc, lim_sup_perc = aplicar_capping(original, 'percentile')\n",
    "    \n",
    "    # Crear DataFrame comparativo\n",
    "    comparacion = pd.DataFrame({\n",
    "        'original': original,\n",
    "        'winsorized': winsorized,\n",
    "        'capped_iqr': capped_iqr,\n",
    "        'capped_percentile': capped_percentile\n",
    "    })\n",
    "    \n",
    "    return comparacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_columns:\n",
    "    # Aplicar a una columna de ejemplo\n",
    "    comparacion = comparar_tecnicas_outliers(df, col)\n",
    "\n",
    "    print(\" COMPARACI√ìN DE T√âCNICAS \")\n",
    "    print(f\"Columna: {col}\")\n",
    "    print(\"\\nEstad√≠sticas descriptivas:\")\n",
    "    print(comparacion.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc4eb46",
   "metadata": {},
   "source": [
    "# ** Gu√≠a Te√≥rica: Cu√°ndo Usar Winsorizing vs IQR vs Percentile**\n",
    "\n",
    "## ** Comparativa Conceptual**\n",
    "\n",
    "| M√©todo | Concepto | Robustez | Preservaci√≥n Datos | Casos Ideales |\n",
    "|--------|----------|-----------|-------------------|---------------|\n",
    "| **Winsorizing** | Reemplaza extremos con percentiles | Media | Alta | Datos con colas pesadas |\n",
    "| **IQR (Capping)** | Corta valores beyond ¬±1.5√óIQR | Alta | Media | Distribuciones sim√©tricas |\n",
    "| **Percentile** | Corta en percentiles fijos | Media | Baja | Conocimiento del dominio |\n",
    "\n",
    "---\n",
    "\n",
    "## ** WINSORIZING - Cu√°ndo Usar**\n",
    "\n",
    "### **Casos Ideales:**\n",
    "# Ejemplos donde WINSORIZING es mejor:\n",
    "\n",
    "-  Datos financieros (retornos, precios)\n",
    "    * \"Retornos de acciones: -10%, 2%, 1%, 15%, -8%, 25%, -50%\"\n",
    "    * \"‚Üí Winsorizing (5%, 95%) preserva la volatilidad pero controla extremos\"\n",
    "\n",
    "-  Mediciones m√©dicas (valores biol√≥gicos)\n",
    "    * \"Presi√≥n arterial: 120, 118, 122, 180, 115, 200, 110\"\n",
    "    * \"‚Üí Los extremos pueden ser reales pero raros - winsorizing los suaviza\"\n",
    "\n",
    "-  Cuando importa la forma de la distribuci√≥n\n",
    "    * \"An√°lisis de distribuci√≥n de ingresos\"\n",
    "    * \"‚Üí Winsorizing mantiene la forma general mientras controla outliers\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04301980",
   "metadata": {},
   "source": [
    "# **Gu√≠a Te√≥rica: Cu√°ndo Usar Winsorizing vs IQR vs Percentile**\n",
    "\n",
    "## **WINSORIZING - Cu√°ndo Usar**\n",
    "\n",
    "### **Casos Ideales:**\n",
    "\n",
    "**1. Datos con colas pesadas o distribuciones asim√©tricas**\n",
    "- Cuando los outliers son valores reales pero extremos\n",
    "- Ejemplo: ingresos, precios de activos financieros, mediciones biol√≥gicas\n",
    "- Preserva la forma de la distribuci√≥n mientras controla valores extremos\n",
    "\n",
    "**2. Cuando se necesita mantener el tama√±o de la muestra**\n",
    "- No reduce el n√∫mero de observaciones\n",
    "- Reemplaza valores extremos en lugar de eliminarlos\n",
    "- Importante en muestras peque√±as o an√°lisis estad√≠sticos que requieren n constante\n",
    "\n",
    "**3. An√°lisis donde la varianza es importante**\n",
    "- Mantiene mejor la variabilidad original que el capping\n",
    "- Ideal para an√°lisis param√©tricos posteriores\n",
    "\n",
    "**4. Cuando los valores extremos contienen informaci√≥n valiosa**\n",
    "- Los outliers son casos raros pero leg√≠timos\n",
    "- Ejemplo: pacientes con respuestas excepcionales a tratamientos\n",
    "\n",
    "---\n",
    "\n",
    "## **IQR (Capping) - Cu√°ndo Usar**\n",
    "\n",
    "### **Casos Ideales:**\n",
    "\n",
    "**1. Distribuciones aproximadamente normales o sim√©tricas**\n",
    "- Cuando los datos siguen una distribuci√≥n en forma de campana\n",
    "- El m√©todo IQR asume cierta simetr√≠a en los datos\n",
    "\n",
    "**2. Outliers claramente err√≥neos o irrelevantes**\n",
    "- Errores de medici√≥n, entrada de datos o instrumentaci√≥n\n",
    "- Valores que no representan el fen√≥meno de inter√©s\n",
    "- Ejemplo: edad registrada como 200 a√±os\n",
    "\n",
    "**3. Control de calidad y procesos industriales**\n",
    "- Cuando existen l√≠mites de especificaci√≥n conocidos\n",
    "- Valores fuera de rangos fisiol√≥gicos o operativos aceptables\n",
    "\n",
    "**4. Preparaci√≥n de datos para machine learning**\n",
    "- Algoritmos sensibles a valores extremos\n",
    "- Modelos que asumen distribuci√≥n normal o rangos acotados\n",
    "\n",
    "**5. Cuando se busca un m√©todo estandarizado y ampliamente aceptado**\n",
    "- IQR es f√°cil de explicar y entender\n",
    "- M√©todo robusto que no depende de supuestos de normalidad\n",
    "\n",
    "---\n",
    "\n",
    "## **M√âTODO POR PERCENTILE - Cu√°ndo Usar**\n",
    "\n",
    "### **Casos Ideales:**\n",
    "\n",
    "**1. Conocimiento previo del dominio**\n",
    "- Cuando se sabe que valores beyond ciertos percentiles no son v√°lidos\n",
    "- Ejemplo: en antropometr√≠a, estaturas beyond percentil 1% o 99% pueden ser errores\n",
    "\n",
    "**2. Datos con distribuciones muy irregulares**\n",
    "- Cuando IQR no funciona bien por asimetr√≠a extrema\n",
    "- Distribuciones multimodales o con gaps\n",
    "\n",
    "**3. Benchmarking contra est√°ndares de la industria**\n",
    "- Cuando existen percentiles de referencia establecidos\n",
    "- Ejemplo: percentiles de crecimiento infantil, percentiles financieros\n",
    "\n",
    "**4. Cuando se requieren l√≠mites fijos y consistentes**\n",
    "- Los percentiles no cambian entre diferentes muestras de la misma poblaci√≥n\n",
    "- √ötil para comparaciones longitudinales\n",
    "\n",
    "---\n",
    "\n",
    "## **Comparaci√≥n de Robustez**\n",
    "\n",
    "**Winsorizing:**\n",
    "- Menos distorsi√≥n de la distribuci√≥n original\n",
    "- Mantiene mejor las propiedades estad√≠sticas\n",
    "- M√°s suave con los valores extremos\n",
    "\n",
    "**IQR:**\n",
    "- Altamente robusto a outliers\n",
    "- No depende de la media ni desviaci√≥n est√°ndar\n",
    "- Funciona bien con distribuciones no normales\n",
    "\n",
    "**Percentile:**\n",
    "- Poco robusto con muestras peque√±as\n",
    "- Sensible a la elecci√≥n arbitraria de percentiles\n",
    "- Puede eliminar datos v√°lidos\n",
    "\n",
    "---\n",
    "\n",
    "## **Recomendaciones por Contexto**\n",
    "\n",
    "**Investigaci√≥n Cient√≠fica:**\n",
    "- Winsorizing para preservar informaci√≥n\n",
    "- IQR cuando los outliers son errores de medici√≥n\n",
    "\n",
    "**Finanzas y Econom√≠a:**\n",
    "- Winsorizing para mantener las colas de distribuci√≥n\n",
    "- Percentiles para an√°lisis de riesgo (VaR)\n",
    "\n",
    "**Machine Learning:**\n",
    "- IQR para la mayor√≠a de casos\n",
    "- Winsorizing cuando los outliers contienen informaci√≥n predictiva\n",
    "\n",
    "**Control de Calidad:**\n",
    "- IQR o percentiles basados en especificaciones\n",
    "- L√≠mites definidos por el proceso\n",
    "\n",
    "---\n",
    "\n",
    "## **Consideraciones Pr√°cticas**\n",
    "\n",
    "**Tama√±o de Muestra:**\n",
    "- Muestras peque√±as: Winsorizing o IQR\n",
    "- Muestras grandes: Cualquier m√©todo funciona bien\n",
    "\n",
    "**Prop√≥sito del An√°lisis:**\n",
    "- An√°lisis exploratorio: Probar m√∫ltiples m√©todos\n",
    "- An√°lisis inferencial: Winsorizing suave\n",
    "- Modelado predictivo: IQR o eliminaci√≥n\n",
    "\n",
    "**Distribuci√≥n de los Datos:**\n",
    "- Sim√©trica: IQR\n",
    "- Asim√©trica: Winsorizing\n",
    "- Multimodal: Percentiles espec√≠ficos por modo\n",
    "\n",
    "La elecci√≥n depende fundamentalmente de si consideramos que los outliers representan informaci√≥n valiosa o deben ser tratados como anomal√≠as a controlar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "86400_data_science_i_diplomatura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
